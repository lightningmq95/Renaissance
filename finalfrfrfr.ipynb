{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import easyocr\n",
    "import assemblyai as aai\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "aai.settings.api_key = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file_path):\n",
    "    config = aai.TranscriptionConfig(speaker_labels=True)\n",
    "    transcript = aai.Transcriber().transcribe(audio_file_path, config)\n",
    "    results = []\n",
    "    for utterance in transcript.utterances:\n",
    "        start = utterance.start / 1000\n",
    "        end = utterance.end / 1000\n",
    "        result = (start, end, utterance.speaker, utterance.text)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_contour_region(frame, x, y, w, h):\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "    results = reader.readtext(roi)\n",
    "    text = ' '.join([result[1] for result in results])\n",
    "    return text.strip() if text.strip() else \"Unknown Speaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_transcript(video_path, meeting_type):\n",
    "    \"\"\"\n",
    "    Process video and return transcript with speaker identification\n",
    "    Args:\n",
    "        video_path (str): Path to video file\n",
    "        meeting_type (str): '1' for Google Meet, '2' for Zoom\n",
    "    Returns:\n",
    "        list: List of dicts with speaker and transcript\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    transcription_results = transcribe_audio(video_path)\n",
    "    transcript_list = []\n",
    "\n",
    "    for start_time, end_time, speaker, text in transcription_results:\n",
    "        text_counter = Counter()\n",
    "        duration = end_time - start_time\n",
    "        analysis_end = start_time + min(duration, 10)\n",
    "\n",
    "        for t in np.arange(start_time, analysis_end, 0.5):\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC, t * 1000)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            if meeting_type == '1':  # Google Meet\n",
    "                mask = cv2.inRange(hsv, np.array([100,50,50]), np.array([130,255,255]))\n",
    "            else:  # Zoom\n",
    "                mask = cv2.inRange(hsv, np.array([40,50,50]), np.array([80,255,255]))\n",
    "\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "            if len(cnts) > 0:\n",
    "                area = max(cnts, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(area)\n",
    "                speaker_name = process_contour_region(frame, x, y, w, h)\n",
    "                text_counter[speaker_name] += 1\n",
    "\n",
    "        most_common_speaker = text_counter.most_common(1)[0][0] if text_counter else \"Unknown Speaker\"\n",
    "        \n",
    "        transcript_dict = {\"start_minutes\": start_time, \"end_minutes\": end_time, \"speaker\": most_common_speaker, \"text\": text}\n",
    "        transcript_list.append(transcript_dict)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return transcript_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_video_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserver/videos/new1.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mprocess_video_transcript\u001b[1;34m(video_path, meeting_type)\u001b[0m\n\u001b[0;32m     17\u001b[0m analysis_end \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmin\u001b[39m(duration, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(start_time, analysis_end, \u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_MSEC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_video_transcript(\"server/videos/new1.mp4\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
